import os
import time
import h5py
import pickle
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
from scipy import misc, ndimage
from sklearn import model_selection, preprocessing, metrics
from sklearn.utils import shuffle
from skimage import transform
from tqdm import tqdm
from keras.models import Model, load_model
from keras.layers import *
from keras.optimizers import *
from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard
from keras import backend as K
from keras.losses import binary_crossentropy


DATA_PATH = "./data"
TRAIN_PATH = os.path.join(DATA_PATH, 'train')
TEST_PATH = os.path.join(DATA_PATH, 'test')
TRAIN_MASKS_PATH = os.path.join(DATA_PATH, 'train_mask_dilate')
TRAIN_MASKS_CSV_PATH = os.path.join(DATA_PATH, 'train_mask.csv')
ASSETS_PATH = os.path.join(DATA_PATH, 'assets')
MODELS_PATH = os.path.join(ASSETS_PATH, 'models')
TENSORBOARD_PATH = os.path.join(ASSETS_PATH, 'tensorboard')

train_masks_df = pd.read_csv(TRAIN_MASKS_CSV_PATH)
print('TRAIN_MASKS_CSV_PATH:', TRAIN_MASKS_CSV_PATH)
print('train_masks_df.shape', train_masks_df.shape)
# print('values:', train_masks_df.mask.values)

# Constants
HEIGHT_ORIG = 1024
WIDTH_ORIG = 512
CHANNELS_ORIG = 1

HEIGHT = 1024
WIDTH = 512
CHANNELS = 1
new_shape = (HEIGHT, WIDTH, CHANNELS)
mask_shape = (new_shape[0], new_shape[1], 1)

def get_img_id(img_path):
    ID, ext = os.path.splitext(img_path)
    return ID
    # return img_path[:15]

train_files_list = os.listdir(TRAIN_PATH)
img_ids = list(map(get_img_id, train_files_list))
print('img_ids:', img_ids)

# img_ids = list(map(get_img_id, list(train_masks_df.mask.values)))


def load_image_disk(img_id, folder=TRAIN_PATH):
    img = misc.imread(os.path.join(folder, img_id + ".bmp"))
    if len(img.shape) == 2:
        img = img.reshape(img.shape[0], img.shape[1], 1)
    return img


def get_image(img_id):
    return train_imgs[img_id]

# Return mask as 1/0 binary img with single channel
def load_mask_disk(img_id, folder=TRAIN_MASKS_PATH, filetype='bmp'):
    mask = misc.imread(os.path.join(folder, "{}_l.{}".format(img_id, filetype)),
                       flatten=True)
    mask[mask < 128] = 1
    mask[mask > 129] = 0
    if len(mask.shape) == 2:
        mask = mask.reshape(mask.shape[0], mask.shape[1], 1)
    return mask


def get_mask(img_id):
    return train_masks[img_id]


# Helper functions to plot car, mask, masked_car
def plot_image(img_id):
    img = misc.imread(os.path.join(TRAIN_PATH, img_id + ".bmp"))
    imgplot = plt.imshow(img)
    plt.axis('off')
    plt.show()


def plot_mask(img_id, folder=TRAIN_MASKS_PATH, filetype='gif', ax=None):
    mask = misc.imread(os.path.join(folder, "{}_mask.{}".format(img_id, filetype)))
    if ax == None:
        imgplot = plt.imshow(mask)
        plt.axis('off')
        plt.show()
    else:
        ax.imshow(mask)
        ax.axis('off')

def plot_masked_image(img_id, ax=None):
    img = misc.imread(os.path.join(TRAIN_PATH, img_id + ".bmp"))
    mask = misc.imread(os.path.join(TRAIN_MASKS_PATH, img_id + "_l.bmp"))
    mask = mask[:, :, 0:3]
    mask[mask == 255] = 1
    masked_img = img * mask
    if ax == None:
        imgplot = plt.imshow(masked_img)
        plt.axis('off')
        plt.show()
    else:
        ax.imshow(masked_img)
        ax.axis('off')

def gray2rgb(img):
    img = np.squeeze(img)
    w, h = img.shape
    ret = np.empty((w, h, 3), dtype=np.uint8)
    ret[:, :, 0] = img
    ret[:, :, 1] = img
    ret[:, :, 2] = img
    return ret


def resize_img(img, new_s=new_shape):
    return transform.resize(img, new_s)


train_imgs = {}
for img_path in tqdm(os.listdir(TRAIN_PATH)):
    img_id = get_img_id(img_path)
    # train_imgs[img_id] = cv2.resize(load_image_disk(img_id), (new_shape[0], new_shape[1]))
    img_temp = cv2.resize(load_image_disk(img_id), (new_shape[0], new_shape[1]))
    if len(img_temp.shape) == 2:
        img_temp = img_temp.reshape(img_temp.shape[0], img_temp.shape[1], 1)
        train_imgs[img_id] = img_temp
    else:
        train_imgs[img_id] = img_temp
    # print('img_temp.shape:', img_temp.shape)

def get_mask_img_id(mask_path):
    path_str = str(mask_path)
    return path_str.split('_l', 1)[0]

train_masks = {}
for img_path in tqdm(os.listdir(TRAIN_MASKS_PATH)):
    img_id = get_mask_img_id(img_path)
    # print('img_id:', img_id)
    train_masks[img_id] = np.expand_dims(cv2.resize(load_mask_disk(img_id),
                                                    (new_shape[0], new_shape[1])), axis=2)

def randomHueSaturationValue(image, hue_shift_limit=(-180, 180),
                             sat_shift_limit=(-255, 255),
                             val_shift_limit=(-255, 255), u=0.5):
    if np.random.random() < u:
        image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
        h, s, v = cv2.split(image)
        hue_shift = np.random.uniform(hue_shift_limit[0], hue_shift_limit[1])
        h = cv2.add(h, hue_shift)
        sat_shift = np.random.uniform(sat_shift_limit[0], sat_shift_limit[1])
        s = cv2.add(s, sat_shift)
        val_shift = np.random.uniform(val_shift_limit[0], val_shift_limit[1])
        v = cv2.add(v, val_shift)
        image = cv2.merge((h, s, v))
        image = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)
    return image


def randomShiftScaleRotate(image, mask,
                           shift_limit=(-0.0625, 0.0625),
                           scale_limit=(-0.1, 0.1),
                           rotate_limit=(-45, 45), aspect_limit=(0, 0),
                           borderMode=cv2.BORDER_REFLECT_101, u=0.5):

    if len(image.shape) == 2:
        image = image.reshape(image.shape[0], image.shape[1], 1)

    if np.random.random() < u:
        height, width, channel = image.shape

        angle = np.random.uniform(rotate_limit[0], rotate_limit[1])  # degree
        scale = np.random.uniform(1 + scale_limit[0], 1 + scale_limit[1])
        aspect = np.random.uniform(1 + aspect_limit[0], 1 + aspect_limit[1])
        sx = scale * aspect / (aspect ** 0.5)
        sy = scale / (aspect ** 0.5)
        dx = round(np.random.uniform(shift_limit[0], shift_limit[1]) * width)
        dy = round(np.random.uniform(shift_limit[0], shift_limit[1]) * height)

        cc = np.math.cos(angle / 180 * np.math.pi) * sx
        ss = np.math.sin(angle / 180 * np.math.pi) * sy
        rotate_matrix = np.array([[cc, -ss], [ss, cc]])

        box0 = np.array([[0, 0], [width, 0], [width, height], [0, height], ])
        box1 = box0 - np.array([width / 2, height / 2])
        box1 = np.dot(box1, rotate_matrix.T) + np.array([width / 2 + dx, height / 2 + dy])

        box0 = box0.astype(np.float32)
        box1 = box1.astype(np.float32)
        mat = cv2.getPerspectiveTransform(box0, box1)
        image = cv2.warpPerspective(image, mat, (width, height), flags=cv2.INTER_LINEAR,
                                    borderMode=borderMode,
                                    borderValue=(0, 0, 0,))
        mask = cv2.warpPerspective(mask, mat, (width, height), flags=cv2.INTER_LINEAR,
                                   borderMode=borderMode,
                                   borderValue=(0, 0, 0,))
        if len(mask.shape) == 2:
            mask = np.expand_dims(mask, axis=2)

    return image, mask


def randomHorizontalFlip(image, mask, u=0.5):
    if np.random.random() < u:
        image = cv2.flip(image, 1)
        mask = cv2.flip(mask, 1)

    return image, mask


def generate_training_batch(data, batch_size):
    while True:
        X_batch = []
        Y_batch = []
        batch_ids = np.random.choice(data,
                                     size=batch_size,
                                     replace=False)
        for idx, img_id in enumerate(batch_ids):
            x = get_image(img_id)
            y = get_mask(img_id)
            # x, y = randomShiftScaleRotate(x, y,
            #                               shift_limit=(-0.0625, 0.0625),
            #                               scale_limit=(-0.1, 0.1),
            #                               rotate_limit=(-0, 0))
            #             x = randomHueSaturationValue(x,
            #                                hue_shift_limit=(-50, 50),
            #                                sat_shift_limit=(-5, 5),
            #                                val_shift_limit=(-15, 15))
            X_batch.append(x)
            Y_batch.append(y)
        X = np.asarray(X_batch, dtype=np.float32)
        Y = np.asarray(Y_batch, dtype=np.float32)
        yield X, Y


def generate_validation_batch(data, batch_size):
    while True:
        X_batch = []
        Y_batch = []
        batch_ids = np.random.choice(data,
                                     size=batch_size,
                                     replace=False)
        for idx, img_id in enumerate(batch_ids):
            x = get_image(img_id)
            y = get_mask(img_id)
            X_batch.append(x)
            Y_batch.append(y)
        X = np.asarray(X_batch, dtype=np.float32)
        Y = np.asarray(Y_batch, dtype=np.float32)
        yield X, Y


def generate_validation_data_seq(data):
    idx = 0
    while True:
        img_id = data[idx]
        X = get_image(img_id)
        Y = get_mask(img_id)
        yield img_id, X, Y
        idx += 1
        if idx >= len(data):
            break


def get_model_memory_usage(batch_size, model):
    from keras import backend as K

    shapes_mem_count = 0
    for l in model.layers:
        single_layer_mem = 1
        for s in l.output_shape:
            if s is None:
                continue
            single_layer_mem *= s
        shapes_mem_count += single_layer_mem

    trainable_count = int(np.sum([K.count_params(p) for p in set(model.trainable_weights)]))
    non_trainable_count = int(np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))

    total_memory = 4 * batch_size * (shapes_mem_count + trainable_count + non_trainable_count)
    gbytes = round(total_memory / (1024 ** 3), 3)
    mbytes = round(total_memory / (1024 ** 2), 3)

    print('trainable_count', trainable_count, 'non_trainable_count', non_trainable_count,
          'gbytes', gbytes, 'mbytes', mbytes)


def down(filters, input_):
    down_ = Conv2D(filters, (3, 3), padding='same')(input_)
    down_ = BatchNormalization(epsilon=1e-4)(down_)
    down_ = Activation('relu')(down_)
    down_ = Conv2D(filters, (3, 3), padding='same')(down_)
    down_ = BatchNormalization(epsilon=1e-4)(down_)
    down_res = Activation('relu')(down_)
    down_pool = MaxPooling2D((2, 2), strides=(2, 2))(down_)
    return down_pool, down_res


def up(filters, input_, down_):
    up_ = UpSampling2D((2, 2))(input_)
    up_ = concatenate([down_, up_], axis=3)
    up_ = Conv2D(filters, (3, 3), padding='same')(up_)
    up_ = BatchNormalization(epsilon=1e-4)(up_)
    up_ = Activation('relu')(up_)
    up_ = Conv2D(filters, (3, 3), padding='same')(up_)
    up_ = BatchNormalization(epsilon=1e-4)(up_)
    # up_ = Activation('relu')(up_)
    # up_ = Conv2D(filters, (3, 3), padding='same')(up_)
    # up_ = BatchNormalization(epsilon=1e-4)(up_)
    up_ = Activation('relu')(up_)
    return up_


def get_unet_1024(input_shape=(WIDTH, HEIGHT, CHANNELS), num_classes=1):
# def get_unet_1024(input_shape=(HEIGHT, WIDTH, CHANNELS), num_classes=1):
    inputs = Input(shape=input_shape)

    # down0b, down0b_res = down(8, inputs)
    down0a, down0a_res = down(16, inputs)
    down0, down0_res = down(32, down0a)
    down1, down1_res = down(64, down0)
    down2, down2_res = down(128, down1)
    down3, down3_res = down(256, down2)
    down4, down4_res = down(512, down3)

    center = Conv2D(512, (3, 3), padding='same')(down4)
    center = BatchNormalization(epsilon=1e-4)(center)
    center = Activation('relu')(center)
    center = Conv2D(512, (3, 3), padding='same')(center)
    center = BatchNormalization(epsilon=1e-4)(center)
    center = Activation('relu')(center)

    up4 = up(512, center, down4_res)
    up3 = up(256, up4, down3_res)
    up2 = up(128, up3, down2_res)
    up1 = up(64, up2, down1_res)
    up0 = up(32, up1, down0_res)
    up0a = up(16, up0, down0a_res)
    # up0b = up(8, up0a, down0b_res)

    #final_conv1 = Conv2D(16, (3, 3), padding='same', activation='relu', name='final_conv1')(up0a)
    classify = Conv2D(num_classes, (1, 1), activation='sigmoid', name='final_layer')(up0a)

    model = Model(inputs=inputs, outputs=classify)

    return model


def dice_coef(y_true, y_pred, smooth=1):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)

    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)


def dice_coef_loss(y_true, y_pred):
    return 1 - dice_coef(y_true, y_pred)


def bce_dice_loss(y_true, y_pred):
    return binary_crossentropy(y_true, y_pred) + dice_coef_loss(y_true, y_pred)


BATCH_SIZE = 4

# Training new model
ts = str(int(time.time()))
model_name = 'malhot'
num_epochs = 60
steps_per_epoch = int(len(img_ids) * 0.8 / BATCH_SIZE)
run_name = 'model={}-BS={}-num_epoch={}-steps={}-ts={}'.format(model_name,
                                                               BATCH_SIZE,
                                                               num_epochs,
                                                               steps_per_epoch,
                                                               ts)
tensorboard_loc = os.path.join(TENSORBOARD_PATH, run_name)
checkpoint_loc = os.path.join(MODELS_PATH, 'model-{}-weights.h5'.format(ts))

earlyStopping = EarlyStopping(monitor='val_loss',
                              patience=2,
                              verbose=1,
                              min_delta=0.000001,
                              mode='min', )

modelCheckpoint = ModelCheckpoint(checkpoint_loc,
                                  monitor='val_loss',
                                  save_best_only=True,
                                  mode='min',
                                  verbose=1,
                                  save_weights_only=True)

tensorboard = TensorBoard(log_dir=tensorboard_loc, histogram_freq=0,
                          write_graph=True, write_images=True)

# callbacks_list = [modelCheckpoint, earlyStopping, tensorboard]
callbacks_list = [modelCheckpoint, tensorboard]

model = get_unet_1024()
model.compile(loss=bce_dice_loss, optimizer=Adam(lr=1e-4), metrics=[dice_coef])
print(model.summary())
get_model_memory_usage(BATCH_SIZE, model)

train_ids, validation_ids = model_selection.train_test_split(img_ids, random_state=42,
                                                             test_size=0.20)
train_generator = generate_training_batch(train_ids, BATCH_SIZE)
valid_generator = generate_validation_batch(validation_ids, BATCH_SIZE)
VALIDATION_STEPS = int(len(validation_ids) / BATCH_SIZE)

print('Starting run {}'.format(run_name))
history = model.fit_generator(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=num_epochs,
    callbacks=callbacks_list,
    verbose=1,
    validation_data=valid_generator,
    validation_steps=VALIDATION_STEPS)

model_path = os.path.join(MODELS_PATH, 'model-{}.h5'.format(ts))
history_path = os.path.join(MODELS_PATH, 'model-{}.history'.format(ts))
model.save(model_path)
pickle.dump(history.history, open(history_path, "wb"))
print('Saved model at {}'.format(model_path))
print('Saved model history at {}'.format(history_path))

